{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image and Text Generation\n",
    "\n",
    "Other then the tasks mentioned previously, new uprising area in computer vision is image generation and synthesis. \n",
    "\n",
    "## Image understanding\n",
    "\n",
    "So far tried to understand what is in an image. But there are cases we need to understand what is happening inside of an image (like interactions between objects). There are several techniques we can use for that and some of them are as below.\n",
    "\n",
    "### Embeddings\n",
    "\n",
    "In early Vision applications, usage of last hidden layer values as embedding was popular. This is easy to handle since embeddings comes as a secondary output of training process. But it has 2 major issues.\n",
    "\n",
    "1. To create this type of embedding, it is needed to have a very large dataset. Also embeddings will only work in categories found in the trained dataset.\n",
    "\n",
    "2. These Embeddings will discard most of the information provided in the image since it will only consider the labels provided for each of the training image. So embeddings will not contain details that are unrelated to original task model was trained on.\n",
    "\n",
    "\n",
    "### Auxiliary Learning Tasks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
