{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Quality check and Evaluation\n",
    "\n",
    "Once we build and train a ML model, next important part is to analyze its performance. In business cases no one cares about the how cool your model architecture or techniques you used. All they would care about is overrall model quality and how it would hold up against the real world data.\n",
    "\n",
    "Therefore to analyze a model, there are several solutions introduced by researchers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "A tool provided by tensorflow to visualize models realtime. It can monitor model training matrics, evaluation matrics and even inferencing details as well. Since this have interactive capabilities, users can simply change values of various parameters and check the model behaviour easily.\n",
    "\n",
    "#### Weight Histograms\n",
    "\n",
    "    This is an interesting graph which shows how the weights and other scaler quantities that have too many values to inspect individually varies over the training period. \n",
    "\n",
    "    If we think about how the weights were initialized in normal neural network, most probably it would be uniform random intialization. But with each training cycle weight values would get slightly changed and therefore overall value distribution would change as well. In genaral we expect the weight values to revolve around a normal distribution (Central Limit Theorem).\n",
    "\n",
    "    So when we have a weight histogram of our model, we can identify odd patterns of weight distributions like more zero values, constant distribution etc. and act to fix those issues.\n",
    "\n",
    "\n",
    "Other than that, tensor board provides functionality to visualize the model graph and also to explore the data as well.\n",
    "\n",
    "To use tensorboard in our model training process (tensorflow keras) we can include it as a callback function for the model compilation. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sliced Evaluation\n",
    "\n",
    "In today world Machine learning projects, it is important to keep the fairness to all people. There are cases some minorities get weird outputs in ML applications, which causes huge misunderstanding between general public and researchers. To avoid such cases it is important to analyze the model behaviour on edge cases.\n",
    "\n",
    "Though there are cases dataset does not include all the possible examples, it is not the only cause. Typical ML models are focused on identifying general patterns of the majority. In cases of small subsets of data, model may overlook the specialities of minorities and will bias the majority values. Therefore it is important to implement ML model while keeping track of such instances.\n",
    "\n",
    "Regulatization, early stopping, prunning and quantization like techniques may cause models to have mentioned like behaviours. To identify such issues we can use Sliced Evaluations. Idea behind this technique is to segment the validation dataset and then use those segments to identify the behavioural patterns of ML models. \n",
    "\n",
    "(This is an active area of research in today ML world called fairness.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68acd5d746db9e112a7343296bb3423d1ae6da35b5d50d333630681f8a968c1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
